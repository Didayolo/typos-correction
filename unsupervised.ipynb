{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    \"\"\"\n",
    "    Order 1 Hidden Markov Model\n",
    "    Attributes\n",
    "    ----------\n",
    "    A : numpy.ndarray\n",
    "        State transition probability matrix\n",
    "    B: numpy.ndarray\n",
    "        Output emission probability matrix with shape(N, number of output types)\n",
    "    pi: numpy.ndarray\n",
    "        Initial state probablity vector\n",
    "    Common Variables\n",
    "    ----------------\n",
    "    obs_seq : list of int\n",
    "        list of observations (represented as ints corresponding to output\n",
    "        indexes in B) in order of appearance\n",
    "    T : int\n",
    "        number of observations in an observation sequence\n",
    "    N : int\n",
    "        number of states\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, A, B, pi):        \n",
    "        if np.any(A<0) | np.any(B<0) | np.any(pi<0) | np.any(A>1) | np.any(B>1) | np.any(pi>1):\n",
    "            return(\"Les paramètres initiaux ne sont pas corrects (des probabilités sont comprises entre 0 et 1)\")\n",
    "        \n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.pi = pi\n",
    "        \n",
    "\n",
    "    def forward(self, Y):\n",
    "        N = self.A.shape[0]\n",
    "        T = len(Y)\n",
    "\n",
    "        alpha = np.zeros([N,T])\n",
    "        alpha[:,0] = self.pi * self.B[:, Y[0]]\n",
    "\n",
    "        for t in range(1,T):\n",
    "            for i in range(N):\n",
    "                alpha[i,t] = self.B[i, Y[t]] * np.sum(alpha[:,t-1] * self.A[:,i])\n",
    "\n",
    "        return alpha\n",
    "\n",
    "    def backward(self, Y):\n",
    "        N = self.A.shape[0]\n",
    "        T = len(Y)\n",
    "\n",
    "        beta = np.zeros([N,T])\n",
    "        beta[:,-1] = 1\n",
    "\n",
    "        for t in range(T-2,-1,-1):\n",
    "            for i in range(N):\n",
    "                beta[i,t] = np.sum(beta[:,t+1] * self.A[i,:] * self.B[:, Y[t+1]])\n",
    "\n",
    "        return beta\n",
    "\n",
    "    def baum_welch_train(self, Y):\n",
    "        N = self.A.shape[0]\n",
    "        T = len(Y)\n",
    "\n",
    "        # Effectuons les etapes de forward et backward\n",
    "        alpha = self.forward(Y)\n",
    "        beta = self.backward(Y)\n",
    "\n",
    "        # Stockons P( Y | theta )\n",
    "        Y_proba = np.sum(alpha[:,-1])\n",
    "\n",
    "        # Calculons gamma\n",
    "        gamma = alpha * beta / Y_proba\n",
    "        \n",
    "        # Calculons xi\n",
    "        xi = np.zeros([T-1, N, N])\n",
    "        for t in range(T-1):\n",
    "            xi[t,:,:] = (alpha[:,t] * self.A.T).T * beta[:, t+1] * self.B[:,Y[t+1]] / Y_proba\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        self.pi = gamma[:,0]\n",
    "        self.A = np.sum(xi,axis = 0)/np.sum(gamma[:,:-1],axis = 1)\n",
    "        \n",
    "        # Problème d'indices ici\n",
    "        for i in range(N):\n",
    "            for t1 in range(T):\n",
    "                self.B[i,t1] = 0\n",
    "                ind = np.argwhere(Y == t1)\n",
    "                self.B += gamma[i,ind]\n",
    "                self.B[i,t1]/= np.sum(gamma[i,:])\n",
    "        \n",
    "        def viterbi(self, Y):\n",
    "            \"\"\"\n",
    "            Returns\n",
    "            -------\n",
    "            V : numpy.ndarray\n",
    "            V [s][t] = Maximum probability of an observation sequence ending\n",
    "                       at time 't' with final state 's'\n",
    "            prev : numpy.ndarray\n",
    "            Contains a pointer to the previous state at t-1 that maximizes\n",
    "            V[state][t]\n",
    "            \"\"\"\n",
    "            N = self.A.shape[0]\n",
    "            T = len(Y)\n",
    "            prev = np.zeros((T - 1, N), dtype=int)\n",
    "\n",
    "            # DP matrix containing max likelihood of state at a given time\n",
    "            V = np.zeros((N, T))\n",
    "            V[:,0] = self.pi * self.B[:,Y[0]]\n",
    "\n",
    "            for t in range(1, T):\n",
    "                for n in range(N):\n",
    "                    seq_probs = V[:,t-1] * self.A[:,n] * self.B[n, Y[t]]\n",
    "                    prev[t-1,n] = np.argmax(seq_probs)\n",
    "                    V[n,t] = np.max(seq_probs)\n",
    "\n",
    "            return V, prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de phrases totales = 30558\n",
      "Nombre de phrases de train = 29057\n",
      "Nombre de phrases de test  = 1501\n"
     ]
    }
   ],
   "source": [
    "path = 'typos-data/'\n",
    "\n",
    "# Données avec 10% de typos\n",
    "train10 = pickle.load(open(path+'train10.pkl', 'rb'))\n",
    "test10 = pickle.load(open(path+'test10.pkl', 'rb'))\n",
    "\n",
    "# Données avec 20% de typos\n",
    "train20 = pickle.load(open(path+'train20.pkl', 'rb'))\n",
    "test20 = pickle.load(open(path+'test20.pkl', 'rb'))\n",
    "\n",
    "train = train10\n",
    "test = test10\n",
    "\n",
    "tot = len(train + test)\n",
    "print (\"Nombre de phrases totales = \" + str(tot))\n",
    "print (\"Nombre de phrases de train = \" + str(len(train)))\n",
    "print (\"Nombre de phrases de test  = \" + str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b',\n",
       " 'y',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'i',\n",
       " 'r',\n",
       " 'o',\n",
       " 'w',\n",
       " 'n',\n",
       " 'a',\n",
       " 'c',\n",
       " 'v',\n",
       " 'o',\n",
       " 'u',\n",
       " 'n',\n",
       " 't']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [[letter[0] for letter in word] for word in train10]\n",
    "texte = [letter for word in temp for letter in word]\n",
    "texte[:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = {'a':0,\n",
    "            'b':1,\n",
    "           'c':2,\n",
    "           'd':3,\n",
    "           'e':4,\n",
    "           'f':5,\n",
    "           'g':6,\n",
    "           'h':7,\n",
    "           'i':8,\n",
    "           'j':9,\n",
    "           'k':10,\n",
    "           'l':11,\n",
    "           'm':12,\n",
    "           'n':13,\n",
    "           'o':14,\n",
    "           'p':15,\n",
    "           'q':16,\n",
    "           'r':17,\n",
    "           's':18,\n",
    "           't':19,\n",
    "           'u':20,\n",
    "           'v':21,\n",
    "           'w':22,\n",
    "           'x':23,\n",
    "           'y':24,\n",
    "           'z':25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "143168\n"
     ]
    }
   ],
   "source": [
    "dic_len = len(np.unique(texte))\n",
    "texte_len = len(texte)\n",
    "print(dic_len)\n",
    "print(texte_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.ones([dic_len,dic_len])/dic_len\n",
    "B = np.ones([dic_len,texte_len])/dic_len\n",
    "pi = np.ones(dic_len)/dic_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 24, 19, 7, 4, 8, 17, 14, 22, 13]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input = [alphabet[letter] for letter in texte]\n",
    "train_input[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hmm = HMM(A=A, \n",
    "          B=B,\n",
    "          pi = pi)\n",
    "\n",
    "hmm.baum_welch_train(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
